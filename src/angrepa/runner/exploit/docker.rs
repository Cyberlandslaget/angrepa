#![allow(clippy::needless_raw_string_hashes)]
use std::{collections::HashMap, pin::Pin};

use angrepa::{
    config,
    db::{Db, DbError},
    models::ExploitModel,
};
use async_trait::async_trait;
use bollard::{
    container::{Config, CreateContainerOptions},
    exec::{CreateExecOptions, StartExecOptions, StartExecResults},
    image::BuildImageOptions,
    service::{BuildInfo, ContainerInspectResponse, ImageId},
    Docker,
};
use futures::{Future, StreamExt};
use rand::RngCore;
use thiserror::Error;
use tracing::{debug, info, trace, warn};

use super::{Exploit, RunLog};

/// how many ticks to wait before killing services
const TIMEOUT_TICK_COUNT: u64 = 1;

#[derive(Error, Debug)]
pub enum DockerError {
    #[error("bollard error")]
    Bollard(#[from] bollard::errors::Error),
    #[error("dockerfile missing cmd")]
    NoCmd,
    #[error("db error")]
    Db(#[from] DbError),
    #[error("flume channel send error")]
    ChannelError(#[from] flume::SendError<String>),
}

#[derive(Debug, Clone)]
pub struct BuiltExploit {
    pub docker: Docker,
    pub image: String,
}

#[derive(Debug)]
/// Has a specific container (i.e. it's "started")
pub struct InitalizedExploit {
    pub docker: Docker,
    pub image: String,
    pub pool: ContainerPool,
    pub cmd: Vec<String>,
}

/// A collection of containers with the same underlying image
/// - uses the number of started execs as a heuristic for load balancing
///   - this assumes all execs take the same amount of time
#[derive(Debug)] // no Clone!!!!
pub struct ContainerPool {
    /// (container_id, number_of_started_execs)
    /// NEVER add containers without resetting ALL counts!!!
    /// HashMap so there are no duplicate IDS
    containers: HashMap<String, u32>,
}

impl ContainerPool {
    // == make pool ==

    fn from_containers(container_ids: &[String]) -> Self {
        let mut containers = HashMap::new();

        for container_id in container_ids {
            containers.insert(container_id.to_owned(), 0);
        }

        Self { containers }
    }

    // looking for add/remove? just make a new pool! :)

    // == get pool (serialize) ==
    pub fn containers(&self) -> Vec<String> {
        self.containers.keys().cloned().collect()
    }

    // == use pool ==

    /// Allocates (returns) a container for running an exploit
    /// - you *must* use this, otherwise internal count gets fucked
    #[must_use]
    fn allocate_container(&mut self) -> &str {
        let (id, cnt) = self
            .containers
            .iter_mut()
            .min_by_key(|(_, count)| **count)
            .unwrap();

        *cnt += 1;

        id.as_str()
    }
}

impl InitalizedExploit {
    pub async fn from_model(
        docker: Docker,
        model: ExploitModel,
        mut db: Db<'_>,
    ) -> Result<Self, DockerError> {
        // expand, then we get unused error if we dont use all fields
        let ExploitModel {
            id: _,
            name: _,
            service: _,
            blacklist: _,
            enabled: _,
            docker_image: image,
            docker_containers,
            pool_size,
        } = model;

        let cmd = docker
            .inspect_image(&image)
            .await?
            .config
            .ok_or(DockerError::NoCmd)?
            .cmd
            .ok_or(DockerError::NoCmd)?;

        // filter away None values (should never even be any but DB limitations)
        let possible_containers: Vec<_> = docker_containers.into_iter().flatten().collect();

        // only take the ones we can inspect
        let mut found_containers = Vec::new();
        for id in possible_containers {
            let inspection = docker.inspect_container(&id, None).await;
            match inspection {
                Ok(ContainerInspectResponse {
                    state: Some(state), ..
                }) => {
                    if !state.running.unwrap_or_default() {
                        info!("Container {} was stopped, starting again.", id);
                        docker.start_container::<&str>(&id, None).await?;
                        info!("Container {} successfully started.", id);
                    }
                    found_containers.push(id);
                }
                Ok(ContainerInspectResponse { state: None, .. }) => {
                    warn!("Container {} has no state", id);
                }
                Err(e) => {
                    warn!("Error inspecting container, dropping. {}: {:?}", id, e);
                }
            }
        }

        let container_pool = ContainerPool::from_containers(&found_containers);

        let is_correct_size = container_pool.containers().len() as i32 == pool_size;

        if is_correct_size {
            Ok(Self {
                docker,
                image,
                pool: container_pool,
                cmd,
            })
        } else {
            warn!("Pool size is inconsistent with acutal number of containers. Making new pool.");

            let exploit = BuiltExploit {
                docker: docker.clone(),
                image,
            };

            let initialized_exploit = exploit.spawn(pool_size as usize).await?;

            // update db! this will eventually result in the dangling
            // containers being stopped/killed

            // by keeping them running for now, we'll get any flags from in
            // progress executions

            db.set_docker_containers(initialized_exploit.pool.containers())?;

            Ok(initialized_exploit)
        }
    }

    // could potentially run this on Drop, but we could end up with "use after free"-ish stuff
    #[allow(dead_code)]
    pub async fn kill(self) -> Result<(), DockerError> {
        for name in self.pool.containers() {
            self.docker.kill_container::<&str>(&name, None).await?;
        }

        Ok(())
    }
}

impl BuiltExploit {
    /// Starts an instance
    pub async fn spawn(&self, cnt: usize) -> Result<InitalizedExploit, DockerError> {
        if cnt > 100 {
            warn!("Insane pool size {}", cnt);
        }

        let gen_name = || {
            format!(
                "instance_pool_{image}_{random}",
                image = self.image,
                random = rand::random::<u32>()
            )
        };

        // first get the cmd
        let inspected = self.docker.inspect_image(&self.image).await?;

        let cmd = inspected
            .config
            .ok_or(DockerError::NoCmd)?
            .cmd
            .ok_or(DockerError::NoCmd)?;

        // override the entrypoint (cmd)
        let config = Config {
            image: Some(self.image.as_str()),
            cmd: Some(vec!["sleep", "infinity"]),
            tty: Some(true),
            ..Default::default()
        };

        let mut container_ids = Vec::new();
        for _ in 0..cnt {
            let options = CreateContainerOptions {
                name: gen_name(),
                ..Default::default()
            };

            let container = self
                .docker
                .create_container(Some(options.clone()), config.clone())
                .await?;

            self.docker
                .start_container::<String>(&container.id, None)
                .await?;

            container_ids.push(container.id);
        }
        let pool = ContainerPool::from_containers(&container_ids);

        Ok(InitalizedExploit {
            docker: self.docker.clone(),
            image: self.image.clone(),
            pool,
            cmd,
        })
    }

    /// make sure nothing is using it :)
    #[allow(dead_code)]
    pub async fn rm_image(self) -> Result<(), DockerError> {
        self.docker.remove_image(&self.image, None, None).await?;
        Ok(())
    }
}

#[async_trait]
impl Exploit for InitalizedExploit {
    type Error = DockerError;

    async fn run(
        &mut self,
        common: &config::Common,
        host: String,
        flagid: String,
    ) -> Result<
        (
            Pin<Box<dyn Future<Output = Result<RunLog, Self::Error>> + std::marker::Send>>,
            flume::Receiver<String>,
        ),
        Self::Error,
    > {
        // the original command
        let cmd = Some({
            let timeout_len = common.tick * TIMEOUT_TICK_COUNT;

            vec![
                "timeout".to_string(),
                "-s9".to_string(),
                format!("{}s", timeout_len),
            ]
            .into_iter()
            .chain(self.cmd.clone())
            .collect()
        });
        let env = Some(vec![format!("IP={host}"), format!("FLAG_ID={flagid}")]);

        let create_options = CreateExecOptions {
            cmd,
            env,
            attach_stdout: Some(true),
            attach_stderr: Some(true), // not sure how to read this
            attach_stdin: Some(false),
            ..Default::default()
        };

        let container = self.pool.allocate_container();
        //trace!("using container {}", container);

        let exec = self.docker.create_exec(container, create_options).await?;

        let start_options = StartExecOptions {
            detach: false,                      // get output
            output_capacity: Some(1024 * 1024), // should be about 128 thousand chars ???
        };

        let docker = self.docker.clone();

        let (tx, rx) = flume::unbounded();

        // a future that doesnt borrow self
        Ok((
            Box::pin(async move {
                let run = docker.start_exec(&exec.id, Some(start_options)).await?;

                let (mut output, _input) = match run {
                    StartExecResults::Attached { output, input } => (output, input),
                    StartExecResults::Detached => unreachable!(),
                };

                while let Some(msg) = output.next().await {
                    let msg = msg?;
                    let msg = msg.to_string();
                    tx.send_async(msg).await?;
                }

                // append exit_code if it's known
                let inspection = docker.inspect_exec(&exec.id).await?;

                match inspection.exit_code {
                    Some(0) => {}
                    None => {}
                    Some(139) => {
                        tx.send_async(
                            "angrepa: execution failed with Segmentation fault".to_string(),
                        )
                        .await?
                    }
                    Some(124) => {
                        tx.send_async("angrepa: execution killed due to timeout".to_string())
                            .await?
                    }
                    Some(137) => {
                        tx.send_async("angrepa: execution sigkilled due to timeout".to_string())
                            .await?
                    }
                    Some(x) => {
                        tx.send_async(format!(
                            "angrepa: exploit failed with unknown exit code {}",
                            x
                        ))
                        .await?;
                    }
                }

                let exit_code = inspection.exit_code.unwrap_or_default() as u8;

                Ok(RunLog { exit_code })
            }),
            rx,
        ))
    }
}

pub struct DockerInstance {
    docker: Docker,
}

impl DockerInstance {
    pub fn new() -> Result<Self, DockerError> {
        Ok(Self {
            docker: Docker::connect_with_local_defaults()?,
        })
    }

    pub async fn build_image(&self, tar: &[u8]) -> Result<(BuiltExploit, String), DockerError> {
        let image_name = {
            let mut bytes = [0u8; 8];
            rand::thread_rng().fill_bytes(&mut bytes);
            format!("exploit_{hash}", hash = hex::encode(bytes))
        };

        debug!("Building new exploit, named '{}'", image_name);

        let options = BuildImageOptions {
            t: image_name.clone(),
            networkmode: String::from("host"),
            memory: Some(1024 * 1024 * 1024 * 8),
            //cpuperiod: Some(100_000), //
            //cpuquota: Some(150_000),  // can get 150ms / 100ms = 1.5 cpu
            ..Default::default()
        };

        let mut stream = self
            .docker
            .build_image(options, None, Some(tar.to_owned().into()));

        let mut build_log = String::new();

        while let Some(msg) = stream.next().await {
            match msg {
                Ok(BuildInfo {
                    stream: Some(stream),
                    id: None,
                    error: None,
                    error_detail: None,
                    status: None,
                    progress: None,
                    progress_detail: None,
                    aux: None,
                }) => {
                    trace!("Progress: {}", stream);
                    build_log += &stream;
                }
                Ok(BuildInfo {
                    stream: None,
                    id: None,
                    error: None,
                    error_detail: None,
                    status: None,
                    progress: None,
                    progress_detail: None,
                    aux: Some(ImageId { id }),
                }) => {
                    trace!("ImageId: {:?}", id);
                    // dont append to log
                }
                Ok(msg) => {
                    trace!("Message: {:?}", msg);
                    build_log += &format!("{:?}", msg);
                }
                Err(e) => {
                    warn!("Error: {:?}", e);
                    return Err(e.into());
                }
            }
        }

        Ok((
            BuiltExploit {
                image: image_name,
                docker: self.docker.clone(),
            },
            build_log,
        ))
    }
}

#[cfg(test)]
mod tests {
    use super::DockerInstance;
    use crate::runner::exploit::Exploit;
    use angrepa::config;
    use color_eyre::eyre::Report;
    use futures::{future::join_all, StreamExt};
    use std::time::Instant;
    use tracing_test::traced_test;

    fn make_tar() -> Result<Vec<u8>, Report> {
        let dockerfile = r###"
FROM python
CMD ["python3", "-c", "import os; print(list(os.environ[x] for x in ['IP', 'FLAG_ID']))"]
"###;
        let mut tar = tar::Builder::new(Vec::new());

        let mut header = tar::Header::new_gnu();
        header.set_size(dockerfile.len() as u64);
        header.set_cksum();
        tar.append_data(&mut header, "Dockerfile", dockerfile.as_bytes())?;
        let tar_data = tar.into_inner()?;

        Ok(tar_data)
    }

    #[tokio::test]
    #[traced_test]
    async fn simple_build() -> Result<(), Report> {
        let tar_data = make_tar()?;

        // build it
        let docker = DockerInstance::new()?;
        let (exploit, _) = docker.build_image(&tar_data).await?;

        let mut exploit = exploit.spawn(1).await?;

        let common = config::Common {
            flag_validity: 1,
            tick: 60,
            ..Default::default()
        };

        // run it
        let (execution, logs) = exploit
            .run(&common, "172.0.1.2".to_string(), "flaghint".to_string())
            .await?;

        let _exec = execution.await?;
        let logs: String = logs.stream().collect().await;

        eprintln!("{}", logs);

        exploit.kill().await.unwrap();

        Ok(())
    }

    #[tokio::test]
    #[traced_test]
    async fn pool_test() -> Result<(), Report> {
        let tar_data = make_tar()?;

        // build it
        let docker = DockerInstance::new().unwrap();
        let (exploit, _) = docker.build_image(&tar_data).await.unwrap();

        // spawn pool container
        let mut pool = exploit.spawn(3).await?;

        const INSTANCES: usize = 10;

        let t0 = Instant::now();

        let mut handles = Vec::new();

        let common = config::Common {
            flag_validity: 1,
            tick: 60,
            ..Default::default()
        };

        for i in 0..INSTANCES {
            let (execution, logs) = pool
                .run(
                    &common,
                    format!("172.0.1.{i}", i = i),
                    "flaghint".to_string(),
                )
                .await?;

            handles.push(tokio::spawn(async move {
                let _result = execution.await.unwrap();
                let logs: String = logs.stream().collect().await;

                eprintln!("{}", logs);
            }))
        }

        let start_time = t0.elapsed();
        let t0 = Instant::now();

        // join
        join_all(handles).await;

        let join_time = t0.elapsed();

        println!("Started {} containers in {:?}", INSTANCES, start_time);
        println!("Joined {} containers in {:?}", INSTANCES, join_time);

        pool.kill().await.unwrap();

        Ok(())
    }
}
